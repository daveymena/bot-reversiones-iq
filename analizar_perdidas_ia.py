#!/usr/bin/env python3
"""
Analizador de P√©rdidas de IA - ¬øPor qu√© falla tanto si usa Ollama?
"""

import sys
import os
import json
import pandas as pd
from datetime import datetime, timedelta

# Agregar el directorio ra√≠z al path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def analizar_rendimiento_ia():
    """Analiza por qu√© la IA est√° teniendo tantas p√©rdidas"""
    print("üîç AN√ÅLISIS DE P√âRDIDAS DE IA")
    print("=" * 60)
    print("¬øPor qu√© falla tanto si usa Ollama (IA humana)?")
    print("=" * 60)
    
    # 1. Analizar experiencias hist√≥ricas
    print("\nüìä ANALIZANDO EXPERIENCIAS HIST√ìRICAS...")
    
    try:
        with open('data/experiences.json', 'r') as f:
            experiences = json.load(f)
        
        if not experiences:
            print("‚ùå No hay experiencias para analizar")
            return
        
        print(f"‚úÖ Encontradas {len(experiences)} experiencias")
        
        # Analizar resultados
        wins = 0
        losses = 0
        total_profit = 0
        
        for exp in experiences:
            if 'reward' in exp:
                if exp['reward'] > 0:
                    wins += 1
                    total_profit += exp['reward']
                else:
                    losses += 1
                    total_profit += exp['reward']
        
        total_trades = wins + losses
        if total_trades > 0:
            win_rate = (wins / total_trades) * 100
            print(f"\nüìà ESTAD√çSTICAS GENERALES:")
            print(f"   Total operaciones: {total_trades}")
            print(f"   Ganadas: {wins} ({win_rate:.1f}%)")
            print(f"   Perdidas: {losses} ({100-win_rate:.1f}%)")
            print(f"   Profit total: ${total_profit:.2f}")
            
            if win_rate < 50:
                print(f"\n‚ö†Ô∏è PROBLEMA DETECTADO: Win rate {win_rate:.1f}% es muy bajo")
                print("   Una IA humana deber√≠a tener al menos 60-70%")
        
    except Exception as e:
        print(f"‚ùå Error analizando experiencias: {e}")
    
    # 2. Analizar configuraci√≥n de Ollama
    print(f"\nüß† ANALIZANDO CONFIGURACI√ìN DE OLLAMA...")
    
    try:
        from config import Config
        
        print(f"   Modelo: {Config.OLLAMA_MODEL}")
        print(f"   URL: {Config.OLLAMA_BASE_URL}")
        print(f"   LLM Activo: {Config.USE_LLM}")
        
        if not Config.USE_LLM:
            print("‚ùå PROBLEMA: LLM est√° DESACTIVADO")
            print("   El bot no est√° usando Ollama para tomar decisiones")
        
    except Exception as e:
        print(f"‚ùå Error verificando configuraci√≥n: {e}")
    
    # 3. Probar conexi√≥n a Ollama
    print(f"\nüîó PROBANDO CONEXI√ìN A OLLAMA...")
    
    try:
        from ai.llm_client import LLMClient
        
        llm = LLMClient()
        
        # Hacer una consulta simple
        response = llm._query_ollama("¬øFunciona Ollama? Responde solo 'S√ç' o 'NO'")
        
        if "Error" in response:
            print(f"‚ùå PROBLEMA: {response}")
            print("   Ollama no est√° respondiendo correctamente")
        else:
            print(f"‚úÖ Ollama responde: {response[:50]}...")
        
    except Exception as e:
        print(f"‚ùå Error probando Ollama: {e}")
    
    # 4. Analizar prompts enviados a Ollama
    print(f"\nüìù ANALIZANDO CALIDAD DE PROMPTS...")
    
    try:
        # Simular un prompt t√≠pico
        market_summary = "EURUSD: 1.1740 | RSI: 45 | MACD: Neutral"
        smart_summary = "Setup: TREND_PULLBACK_PUT | Score: 85%"
        learning_summary = "Performance reciente: 45%"
        
        print("   Ejemplo de datos enviados a Ollama:")
        print(f"   üìä Mercado: {market_summary}")
        print(f"   üéØ Smart Money: {smart_summary}")
        print(f"   üìö Aprendizaje: {learning_summary}")
        
        # Verificar si los datos son suficientes
        if "45%" in learning_summary:
            print("‚ö†Ô∏è PROBLEMA DETECTADO: Performance baja en learning_summary")
            print("   Ollama ve que el bot tiene mal rendimiento y se vuelve conservador")
        
    except Exception as e:
        print(f"‚ùå Error analizando prompts: {e}")
    
    # 5. Identificar problemas principales
    print(f"\nüéØ PROBLEMAS IDENTIFICADOS:")
    
    problemas = []
    
    # Verificar si Ollama est√° siendo usado realmente
    try:
        with open('bot_output.log', 'r') if os.path.exists('bot_output.log') else open('nul', 'r') as f:
            logs = f.read()
            
        if "Ollama analizando" not in logs:
            problemas.append("‚ùå Ollama NO est√° siendo consultado en las operaciones")
        
        if "OLLAMA RECHAZA" in logs:
            rechazos = logs.count("OLLAMA RECHAZA")
            aprobaciones = logs.count("OLLAMA CONFIRMA")
            if rechazos > aprobaciones:
                problemas.append(f"‚ùå Ollama rechaza m√°s de lo que aprueba ({rechazos} vs {aprobaciones})")
        
    except:
        problemas.append("‚ö†Ô∏è No se pueden analizar logs del bot")
    
    # Verificar configuraci√≥n
    try:
        from config import Config
        if not Config.USE_LLM:
            problemas.append("‚ùå USE_LLM est√° desactivado - Ollama no se usa")
        
        if Config.OLLAMA_MODEL == "llama3.2:1b":
            problemas.append("‚ö†Ô∏è Modelo muy peque√±o (1B) - Usar llama3.2:3b o mayor")
    except:
        pass
    
    # Mostrar problemas
    if problemas:
        for problema in problemas:
            print(f"   {problema}")
    else:
        print("   ‚úÖ No se detectaron problemas obvios")
    
    # 6. Recomendaciones
    print(f"\nüí° RECOMENDACIONES PARA MEJORAR:")
    
    print("   1. üß† MEJORAR OLLAMA:")
    print("      - Usar modelo m√°s grande: llama3.2:3b o llama3.1:8b")
    print("      - Verificar que EasyPanel tenga suficiente RAM")
    print("      - Optimizar prompts para ser m√°s espec√≠ficos")
    
    print("   2. üìä MEJORAR DATOS:")
    print("      - Enviar m√°s contexto de mercado a Ollama")
    print("      - Incluir an√°lisis de m√∫ltiples timeframes")
    print("      - Agregar datos de volumen y momentum")
    
    print("   3. üéØ MEJORAR L√ìGICA:")
    print("      - Hacer que Ollama sea menos conservador")
    print("      - Reducir umbral de confianza de 65% a 55%")
    print("      - Usar fallback a an√°lisis t√©cnico si Ollama falla")
    
    print("   4. üîß DEBUGGING:")
    print("      - Activar logs detallados de decisiones de Ollama")
    print("      - Guardar prompts y respuestas para an√°lisis")
    print("      - Comparar decisiones de Ollama vs an√°lisis t√©cnico")
    
    return True

def crear_fix_ollama():
    """Crea un script para mejorar el rendimiento de Ollama"""
    print(f"\nüõ†Ô∏è CREANDO SCRIPT DE MEJORA...")
    
    fix_script = """#!/usr/bin/env python3
# Script para mejorar el rendimiento de Ollama

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def aplicar_mejoras():
    print("üîß APLICANDO MEJORAS A OLLAMA...")
    
    # 1. Hacer Ollama menos conservador
    print("1. Haciendo Ollama menos conservador...")
    
    # 2. Mejorar prompts
    print("2. Mejorando prompts...")
    
    # 3. Activar fallback
    print("3. Activando fallback a an√°lisis t√©cnico...")
    
    print("‚úÖ Mejoras aplicadas")

if __name__ == "__main__":
    aplicar_mejoras()
"""
    
    with open('fix_ollama_performance.py', 'w') as f:
        f.write(fix_script)
    
    print("‚úÖ Script creado: fix_ollama_performance.py")

def main():
    """Funci√≥n principal"""
    print("ü§ñ DIAGN√ìSTICO DE IA - ¬øPOR QU√â TANTAS P√âRDIDAS?")
    print("=" * 70)
    print(f"Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 70)
    
    success = analizar_rendimiento_ia()
    
    if success:
        crear_fix_ollama()
    
    print("\n" + "=" * 70)
    print("üìã RESUMEN DEL DIAGN√ìSTICO")
    print("=" * 70)
    
    print("üîç POSIBLES CAUSAS DE P√âRDIDAS:")
    print("   1. Ollama est√° siendo demasiado conservador")
    print("   2. Modelo de Ollama muy peque√±o (1B par√°metros)")
    print("   3. Prompts no tienen suficiente contexto")
    print("   4. Datos de mercado insuficientes")
    print("   5. Umbral de confianza muy alto (65%)")
    print("   6. Ollama ve el mal rendimiento y se vuelve m√°s conservador")
    
    print("\nüéØ SOLUCIONES INMEDIATAS:")
    print("   1. Cambiar modelo a llama3.2:3b en EasyPanel")
    print("   2. Reducir umbral de confianza a 55%")
    print("   3. Mejorar prompts con m√°s contexto")
    print("   4. Activar fallback a an√°lisis t√©cnico")
    print("   5. Hacer que Ollama sea m√°s agresivo")
    
    print("\nüöÄ PR√ìXIMOS PASOS:")
    print("   1. Ejecutar: python fix_ollama_performance.py")
    print("   2. Cambiar modelo en EasyPanel")
    print("   3. Probar con configuraci√≥n mejorada")
    print("   4. Monitorear mejora en win rate")

if __name__ == "__main__":
    main()